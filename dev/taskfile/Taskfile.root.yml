version: '3'

env:
  SOLO_CLUSTER_NAME: solo
  SOLO_NAMESPACE: solo
  SOLO_CLUSTER_SETUP_NAMESPACE: solo-cluster
  SOLO_DEPLOYMENT: solo-deployment
  NODEJS_VERSION: 20.18.0
  NODES: 5
  RELAY: false
  MIRROR_NODE: false
  HEDERA_EXPLORER: false
  IMAGE: "solo-chaos:latest"

vars:
  UUID:
    sh: uuidgen | tr -d '-' | head -c 8 | tr '[:upper:]' '[:lower:]'
    
tasks:
  deploy-network:
    desc: Deploy a n-node Solo network
    silent: true
    cmds:
      - echo "🚀 Deploying Solo network with NODES={{.NODES}} MIRROR_NODE={{.MIRROR_NODE}} HEDERA_EXPLORER={{.HEDERA_EXPLORER}} RELAY={{.RELAY}}..."
      - task destroy-network
      - |
        if ! kind get clusters | grep -q "{{.SOLO_CLUSTER_NAME}}"; then
          echo "⬇️  Creating Kind cluster {{.SOLO_CLUSTER_NAME}}..."
          kind create cluster --name "{{.SOLO_CLUSTER_NAME}}"
        else
          echo "✅ Kind cluster {{.SOLO_CLUSTER_NAME}} already exists"
        fi
      - task enable-metrics-server
      - task set-proxy
      - echo "🧹 Removing old ~/.solo data..."
      - rm -rf ~/.solo || true
      - echo "⬇️  Initializing Solo..."
      - solo init
      - solo cluster-ref connect --cluster-ref kind-{{.SOLO_CLUSTER_NAME}} --context kind-{{.SOLO_CLUSTER_NAME}}
      - solo deployment create -n "{{.SOLO_NAMESPACE}}" --deployment "{{.SOLO_DEPLOYMENT}}"
      - solo deployment add-cluster --deployment "{{.SOLO_DEPLOYMENT}}" --cluster-ref kind-{{.SOLO_CLUSTER_NAME}} --num-consensus-nodes {{.NODES}}
      - solo node keys --gossip-keys --tls-keys --deployment "{{.SOLO_DEPLOYMENT}}"
      - solo cluster-ref setup -s "{{.SOLO_CLUSTER_SETUP_NAMESPACE}}"
      - solo network deploy --deployment "{{.SOLO_DEPLOYMENT}}"
      - solo node setup --deployment "{{.SOLO_DEPLOYMENT}}"
      - solo node start --deployment "{{.SOLO_DEPLOYMENT}}"
      - |
        {{if .MIRROR_NODE}}
        echo "📡 Deploying Mirror Node..."
        solo mirror-node deploy --deployment "{{.SOLO_DEPLOYMENT}}" --cluster-ref kind-{{.SOLO_CLUSTER_NAME}}
        {{end}}
      - |
        {{if .HEDERA_EXPLORER}}
        echo "🌐 Deploying Explorer..."
        solo explorer deploy --deployment "{{.SOLO_DEPLOYMENT}}" --cluster-ref kind-{{.SOLO_CLUSTER_NAME}}
        {{end}}
      - |
        {{if .RELAY}}
        echo "🔁 Deploying Relay..."
        solo relay deploy -i node1 --deployment "{{.SOLO_DEPLOYMENT}}"
        {{end}}
      - echo "🎉 Solo network deployed with {{.NODES}} nodes! Run 👉 k9s to manage the cluster."
  
  destroy-network:
    desc: Destroy the Solo network and clean up resources
    silent: true
    cmds:
      - echo "💣 Destroying existing Solo network (if any)..."
      - kubectl delete ns "{{.SOLO_NAMESPACE}}" --wait --ignore-not-found || true
      - rm -rf ~/.solo || true
      - echo "✅ Solo network destroyed."
  
  install-chaos-mesh:
    desc: Install Chaos Mesh using Helm (idempotent)
    cmds:
      - helm repo add chaos-mesh https://charts.chaos-mesh.org || true
      - |
        kubectl get ns chaos-mesh >/dev/null 2>&1 || kubectl create ns chaos-mesh
      - |
        if ! helm status chaos-mesh -n chaos-mesh >/dev/null 2>&1; then
          helm install chaos-mesh chaos-mesh/chaos-mesh -n chaos-mesh --version 2.7.2
        fi
      - kubectl get pods --namespace chaos-mesh -l app.kubernetes.io/instance=chaos-mesh || true
      - |
        echo "⏳ Waiting for Chaos Mesh pods to be ready..."
        kubectl wait --namespace chaos-mesh \
          --for=condition=Ready pod \
          --selector=app.kubernetes.io/instance=chaos-mesh \
          --timeout=180s
  
  
  uninstall-chaos-mesh:
    desc: Uninstall Chaos Mesh and clean up resources (idempotent)
    cmds:
      - |
        if helm status chaos-mesh -n chaos-mesh >/dev/null 2>&1; then
          helm uninstall chaos-mesh -n chaos-mesh
        fi
      - |
        if kubectl get ns chaos-mesh >/dev/null 2>&1; then
          kubectl delete ns chaos-mesh --ignore-not-found
        fi
      - kubectl get pods --namespace chaos-mesh -l app.kubernetes.io/instance=chaos-mesh || true
  
  enable-metrics-server:
    desc: Enable metrics server in the Solo network (idempotent)
    cmds:
      - |
        kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
        kubectl patch deployment -n kube-system metrics-server --type='json' \
          -p='[{"op": "add", "path": "/spec/template/spec/containers/0/args/-", "value": "--kubelet-insecure-tls"}]'
        echo "Metrics server is enabled."
  
  
  
  
  
  run-proxy:
    desc: Run a proxy to the Solo network (daemon mode, idempotent)
    cmds:
      - |
        if docker ps -q --filter "name=docker_registry_proxy" | grep -q .; then
          echo "✅ Proxy is already running."
          exit 0
        fi
        echo "Starting docker_registry_proxy..."
        docker run --rm --name docker_registry_proxy -d \
          --net kind --hostname docker-registry-proxy \
          -p 0.0.0.0:3128:3128 \
          -e ENABLE_MANIFEST_CACHE=true \
          -e REGISTRIES="docker.io registry.k8s.io quay.io ghcr.io" \
          -v "$HOME/docker_mirror_cache":/docker_mirror_cache \
          -v "$HOME/docker_mirror_certs":/ca \
          rpardini/docker-registry-proxy:0.6.5
        sleep 5 # Wait for the proxy to start
        echo "✅Proxy is running at localhost:3128"
  
  
  
  
  stop-proxy:
    desc: Stop and remove the proxy container (idempotent)
    cmds:
      - echo "💣 Stopping and removing docker_registry_proxy container (if any)..."
      - |
        if docker ps -q --filter "name=docker_registry_proxy" | grep -q . || true; then
          docker stop docker_registry_proxy || true
          docker rm docker_registry_proxy || true
          echo "✅Stopped and removed docker_registry_proxy container."
        fi
  
  
  
  set-proxy:
    desc: Set up Docker to use the proxy (idempotent)
    cmds:
      - task run-proxy
      - echo "Setting up cluster to use the proxy..."
      - |
        # see: https://github.com/rpardini/docker-registry-proxy
        KIND_NAME={{.SOLO_CLUSTER_NAME}}
        SETUP_URL=http://docker-registry-proxy:3128/setup/systemd
        pids=()
        for NODE in $(kind get nodes --name "$KIND_NAME"); do
        docker exec "$NODE" sh -c "\
        curl "${SETUP_URL}" \
        | sed s/docker\.service/containerd\.service/g \
        | sed '/Environment/ s/$/ \"NO_PROXY=127.0.0.0\/8,10.0.0.0\/8,172.16.0.0\/12,192.168.0.0\/16\"/' \
        | bash" & pids+=("$!") # Configure every node in background
        done
        wait "${pids[@]}" # Wait for all configurations to end
        echo "✅ Cluster configured to use the proxy."
  
  
  
  check-docker:
    desc: Check docker settings
    silent: true
    cmds:
      - task run-proxy
      - |
        echo "🔍 Checking Docker Desktop resources..."
        docker_info=$(docker info --format '{{"{{json .}}"}}')
        mem=$(echo "$docker_info" | jq '.MemTotal' 2>/dev/null || echo 0)
        cpus=$(echo "$docker_info" | jq '.NCPU' 2>/dev/null || echo 0)
        min_mem=$((46 * 1024 * 1024 * 1024))
        min_cpus=10
        if [ "$mem" -lt "$min_mem" ] || [ "$cpus" -lt "$min_cpus" ]; then
          echo "❌ Docker Desktop resources too low: CPUs=$cpus, Mem=$(($mem/1024/1024/1024))GB"
          echo "➡️  Please set at least 48GB RAM and 10 CPUs in Docker Desktop > Settings > Resources."
          exit 1
        else
          echo "✅ Docker Desktop resources OK: CPUs=$cpus, Mem=$(($mem/1024/1024/1024))GB"
        fi
  load-image:
    desc: Load a local Docker image into the Kind cluster
    vars:
      IMAGE: "{{.IMAGE}}"
    cmds:
      - echo "🚚 Loading image {{.IMAGE}} into Kind cluster {{.SOLO_CLUSTER_NAME}}..."
      - kind load docker-image "{{.IMAGE}}" -n "{{.SOLO_CLUSTER_NAME}}"
      - echo "✅ Image {{.IMAGE}} loaded into Kind cluster {{.SOLO_CLUSTER_NAME}}."
  deploy-solo-chaos:
    desc: Deploy Solo Chaos pod using solo-chaos.yml (idempotent)
    cmds:
      - task load-image
      - |
        if ! kubectl get pod solo-chaos --namespace {{.SOLO_NAMESPACE}} >/dev/null 2>&1; then
          echo "🚀 Deploying solo-chaos pod..."
          kubectl apply -f ../k8s/solo-chaos.yml --namespace {{.SOLO_NAMESPACE}}
        else
          echo "✅ solo-chaos pod already exists in namespace {{.SOLO_NAMESPACE}}"
        fi
      - kubectl get pod solo-chaos --namespace {{.SOLO_NAMESPACE}}
  destroy-solo-chaos:
    desc: Destroy the solo-chaos pod (idempotent)
    cmds:
      - echo "💣 Destroying solo-chaos pod (if any)..."
      - |
        if kubectl get pod solo-chaos --namespace {{.SOLO_NAMESPACE}} >/dev/null 2>&1; then
          kubectl delete pod solo-chaos --namespace {{.SOLO_NAMESPACE}} --ignore-not-found
          echo "✅ solo-chaos pod deleted."
        else
          echo "✅ No solo-chaos pod found to delete."
        fi
  deploy-hammer-job:
    desc: Deploy Solo Chaos Hammer job using solo-chaos-hammer-job.yml (idempotent)
    cmds:
      - task destroy-hammer-job
      - task load-image
      - |
        if ! kubectl get job solo-chaos-hammer --namespace {{.SOLO_NAMESPACE}} >/dev/null 2>&1; then
          echo "🚀 Deploying solo-chaos-hammer job..."
          kubectl apply -f ../k8s/solo-chaos-hammer-job.yml --namespace {{.SOLO_NAMESPACE}}
        else
          echo "✅ solo-chaos-hammer job already exists in namespace {{.SOLO_NAMESPACE}}"
        fi
      - kubectl get job solo-chaos-hammer --namespace {{.SOLO_NAMESPACE}}
  destroy-hammer-job:
    desc: Destroy the solo-chaos-hammer job (idempotent)
    cmds:
      - echo "💣 Destroying solo-chaos-hammer job (if any)..."
      - |
        if kubectl get job solo-chaos-hammer --namespace {{.SOLO_NAMESPACE}} >/dev/null 2>&1; then
          kubectl delete job solo-chaos-hammer --namespace {{.SOLO_NAMESPACE}} --ignore-not-found
          echo "✅ solo-chaos-hammer job deleted."
        else
          echo "✅ No solo-chaos-hammer job found to delete."
        fi
  refresh-node:
    desc: Refresh a Solo node by running setup and start (idempotent)
    vars:
      NODE: "{{.NODE}}"
    cmds:
      - echo "🔄 Refreshing Solo node {{.NODE}}..."
      - |
        bash -c "
        if [ -z '{{.NODE}}' ]; then
          echo '❌ NODE variable is required. Usage: task refresh-node -- NODE=node1'
          exit 1
        fi
        " 
        solo node setup --deployment "{{.SOLO_DEPLOYMENT}}" -i {{.NODE}}
        solo node start --deployment "{{.SOLO_DEPLOYMENT}}" -i {{.NODE}}
